---
chunk_index: 120
ref: "212f82f71436"
id: "212f82f7143654ad610eeb981b3ff8d49685b28668dfab516e4f2a7957ee2758"
slug: "chunk-017"
path: "marker/1982 Apple IIe Design Guidelines/chunks/chunk_017.md"
kind: "markdown"
lines: [1, 11]
token_estimate: 833
content_sha256: "3da79c015abb151d43620652fc5d55e886887375a60d88395e3bc82457755449"
compacted: false
heading_path: []
symbol: null
address: null
asset_path: null
---

<!-- Chunk 17 | Source: 1982 Apple IIe Design Guidelines.pdf | Est. Tokens: 2147 -->
Once the users have been profiled and a prototype built, it is time to begin testing.  
Human interfaces are not made; they evolve. Software designers are simply too close to their product, their computer, and have put up with the most abysmal interfaces themselves for too many years to be able to outguess the naive user. Products must be repeatedly tested on "real people". ("Real people" means the target audience: as soon as you find yourself sitting in a meeting with other computerists, all announcing what users will or will not feel/think/do, you are in trouble. Build the prototype and find out.)  
The job of the designer is to do her best to predict the response of the user; the job of the user is to do just the opposite.  
Human interface testing is quite different from the kind of exhaustive "boundary condition" testing used to uncover bugs. You should begin testing as early as possible, using drafted friends, relatives, and new employees, to uncover the really big holes in your design. As you get closer to a finished product, try it out on larger groups drawn from the target population.  
It is imperative that the designers actually watch people use the program. Do not just send off copies of the program and expect written responses. Get the users and the designers in a quiet room together.  
Our testing method is as follows. We set up a room with five to six computer systems. We schedule two to three groups of five to six users at a time to try out the systems (often without their knowing that it is the software rather than the system that we are testing). We have two of the designers in the room. Any fewer, and they miss a lot of what is going on. Any more and the users feel as though there is always someone breathing down their necks.  
The initial ground rules are that no questions will be answered, as by the time the formal testing begins, we can supply a draft of the manual. (Usually by the second group, some glaring defects in the interface have shown up, and we have to give them help getting past the stumbling blocks.)  
Ninety-five percent of the stumbling blocks are found by watching the body language of the users. Watch for squinting eyes, hunched shoulders, shaking heads, and deep, heart-felt sighs. When a user hits a snag, he will assume it is "on account of he is not too bright": he will not report it; he will hide it. Make notes of each problem and where it occurred. Question the users at the end of the session to explore why the problems occurred. Do not make assumptions about why a user became confused. Ask him. You will often be surprised to learn what the user thought the program was doing at the time he got lost.  
We have found that prepared questionnaires handed out at the end of a session are of little value: you will seldom predict the problem areas before testing, and users will lie to spare everyone's feelings. (If you had figured out the problem areas, you would have already fixed them.)  
Generally, two or three groups on one occasion is more than sufficient: patterns will emerge almost immediately. You should have at least one more bank of testing after any major revision; as the next example shows, one often jumps out of the frying pan, into the fire.